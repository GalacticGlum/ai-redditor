{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI-Redditor TPU Training",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "41TPbbfs9dnc",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2335388d-978f-4608-8c48-2142f917af93"
      },
      "source": [
        "#@title Setup Environment\n",
        "#@markdown Clone [ai-redditor](https://github.com/galacticglum/ai-redditor) repostitory and install dependencies.\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "from subprocess import call, STDOUT\n",
        "\n",
        "if call(['git', '-C', './ai-redditor/', 'status'], stderr=STDOUT, stdout=open(os.devnull, 'w')) != 0:\n",
        "  print('Cloning repository.')\n",
        "  username = input('GitHub username: ')\n",
        "  password = getpass('GitHub password: ')\n",
        "  !rm -rf ai-redditor/\n",
        "  !git clone https://{username}:{password}@github.com/galacticglum/ai-redditor.git\n",
        "else:\n",
        "  !git -C ./ai-redditor/ pull\n",
        "\n",
        "print('Installing dependencies')\n",
        "!pip install -r ai-redditor/requirements.txt\n",
        "\n",
        "print('Installing Torch-XLA...')\n",
        "!wget -N https://raw.githubusercontent.com/huggingface/transformers/master/examples/xla_spawn.py\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning repository.\n",
            "GitHub username: galacticglum\n",
            "GitHub password: ··········\n",
            "Cloning into 'ai-redditor'...\n",
            "remote: Enumerating objects: 218, done.\u001b[K\n",
            "remote: Counting objects: 100% (218/218), done.\u001b[K\n",
            "remote: Compressing objects: 100% (165/165), done.\u001b[K\n",
            "remote: Total 218 (delta 87), reused 165 (delta 40), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (218/218), 58.98 KiB | 2.68 MiB/s, done.\n",
            "Resolving deltas: 100% (87/87), done.\n",
            "Installing dependencies\n",
            "Collecting certifi==2020.4.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/2b/26e37a4b034800c960a00c4e1b3d9ca5d7014e983e6e729e33ea2f36426c/certifi-2020.4.5.1-py2.py3-none-any.whl (157kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.6/dist-packages (from -r ai-redditor/requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: click==7.1.2 in /usr/local/lib/python3.6/dist-packages (from -r ai-redditor/requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: idna==2.9 in /usr/local/lib/python3.6/dist-packages (from -r ai-redditor/requirements.txt (line 4)) (2.9)\n",
            "Collecting praw==7.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/39/17251486951815d4514e4a3f179d4f3e7af5f7b1ce8eaba5a3ea61bc91f2/praw-7.0.0-py3-none-any.whl (143kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 11.4MB/s \n",
            "\u001b[?25hCollecting prawcore==1.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/8e/d076cb8f26523f91eef3e75d6cf9143b2f16d67ce7d681a61d0bbc783f49/prawcore-1.3.0-py3-none-any.whl\n",
            "Collecting psaw==0.0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/a2/ad/ba88c5004a6e3434c032a605685d90eb3ad3de355d7ee26869124bf3be73/psaw-0.0.12-py3-none-any.whl\n",
            "Requirement already satisfied: requests==2.23.0 in /usr/local/lib/python3.6/dist-packages (from -r ai-redditor/requirements.txt (line 8)) (2.23.0)\n",
            "Collecting six==1.15.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n",
            "Collecting tqdm==4.46.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/40/058b12e8ba10e35f89c9b1fdfc2d4c7f8c05947df2d5eb3c7b258019fda0/tqdm-4.46.0-py2.py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.8MB/s \n",
            "\u001b[?25hCollecting update-checker==0.17\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/c3/aaf8a162df8e8f9d321237c7c0e63aff95b42d19f1758f96606e3cabb245/update_checker-0.17-py2.py3-none-any.whl\n",
            "Collecting urllib3==1.25.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/e5/df302e8017440f111c11cc41a6b432838672f5a70aa29227bf58149dc72f/urllib3-1.25.9-py2.py3-none-any.whl (126kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 9.4MB/s \n",
            "\u001b[?25hCollecting websocket-client==0.57.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 8.6MB/s \n",
            "\u001b[?25hCollecting wincertstore==0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/67/12f477fa1cc8cbcdc78027c9fb0933ad41daf2e95a29d1cc8f34fe80c692/wincertstore-0.2-py2.py3-none-any.whl\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\u001b[K     |████████████████████████████████| 675kB 8.7MB/s \n",
            "\u001b[?25hCollecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 13.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers->-r ai-redditor/requirements.txt (line 15)) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 17.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers->-r ai-redditor/requirements.txt (line 15)) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers->-r ai-redditor/requirements.txt (line 15)) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers->-r ai-redditor/requirements.txt (line 15)) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers->-r ai-redditor/requirements.txt (line 15)) (0.7)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 28.8MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 50.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r ai-redditor/requirements.txt (line 16)) (3.10.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers->-r ai-redditor/requirements.txt (line 15)) (0.15.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers->-r ai-redditor/requirements.txt (line 15)) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX->-r ai-redditor/requirements.txt (line 16)) (47.3.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=9c3973ac2e2a1a0df0f0ea3916ece9d319b02210b4c9fb812b2355b5ddd1db08\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "\u001b[31mERROR: kaggle 1.5.6 has requirement urllib3<1.25,>=1.21.1, but you'll have urllib3 1.25.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: certifi, prawcore, six, websocket-client, update-checker, praw, psaw, tqdm, urllib3, wincertstore, sacremoses, tokenizers, sentencepiece, transformers, tensorboardX\n",
            "  Found existing installation: certifi 2020.4.5.2\n",
            "    Uninstalling certifi-2020.4.5.2:\n",
            "      Successfully uninstalled certifi-2020.4.5.2\n",
            "  Found existing installation: six 1.12.0\n",
            "    Uninstalling six-1.12.0:\n",
            "      Successfully uninstalled six-1.12.0\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed certifi-2020.4.5.1 praw-7.0.0 prawcore-1.3.0 psaw-0.0.12 sacremoses-0.0.43 sentencepiece-0.1.91 six-1.15.0 tensorboardX-2.0 tokenizers-0.7.0 tqdm-4.46.0 transformers-2.11.0 update-checker-0.17 urllib3-1.25.9 websocket-client-0.57.0 wincertstore-0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "six",
                  "tqdm",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Installing Torch-XLA...\n",
            "--2020-06-22 01:50:13--  https://raw.githubusercontent.com/huggingface/transformers/master/examples/xla_spawn.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1913 (1.9K) [text/plain]\n",
            "Saving to: ‘xla_spawn.py’\n",
            "\n",
            "xla_spawn.py        100%[===================>]   1.87K  --.-KB/s    in 0s      \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2020-06-22 01:50:14 (20.7 MB/s) - ‘xla_spawn.py’ saved [1913/1913]\n",
            "\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  4264  100  4264    0     0  53300      0 --:--:-- --:--:-- --:--:-- 53300\n",
            "Updating TPU and VM. This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-dev20200515 ...\n",
            "Uninstalling torch-1.5.0+cu101:\n",
            "Done updating TPU runtime: <Response [200]>\n",
            "  Successfully uninstalled torch-1.5.0+cu101\n",
            "Uninstalling torchvision-0.6.0+cu101:\n",
            "  Successfully uninstalled torchvision-0.6.0+cu101\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20200515-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][ 91.0 MiB/ 91.0 MiB]                                                \n",
            "Operation completed over 1 objects/91.0 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200515-cp36-cp36m-linux_x86_64.whl...\n",
            "| [1 files][119.5 MiB/119.5 MiB]                                                \n",
            "Operation completed over 1 objects/119.5 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200515-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  2.3 MiB/  2.3 MiB]                                                \n",
            "Operation completed over 1 objects/2.3 MiB.                                      \n",
            "Processing ./torch-nightly+20200515-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200515) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200515) (1.18.5)\n",
            "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.6.0a0+bf2bbd9\n",
            "Processing ./torch_xla-nightly+20200515-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "Successfully installed torch-xla-1.6+2b2085a\n",
            "Processing ./torchvision-nightly+20200515-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200515) (1.6.0a0+bf2bbd9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200515) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200515) (7.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly+20200515) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.7.0a0+a6073f0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  libomp5\n",
            "0 upgraded, 1 newly installed, 0 to remove and 59 not upgraded.\n",
            "Need to get 234 kB of archives.\n",
            "After this operation, 774 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Fetched 234 kB in 0s (1,136 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 144328 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEpjj526Cd_i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "b118ed0b-ceb1-49de-902e-e72dea3dfcdb"
      },
      "source": [
        "#@title Download Datasets\n",
        "#@markdown Download processed [r/WritingPrompts](https://reddit.com/r/writingprompts) and [r/TIFU](https://reddit.com/r/tifu) datasets.\n",
        "\n",
        "!pip install gdown\n",
        "!gdown 'https://drive.google.com/uc?id=1diWV_PmttiuHQy-JQtNVs2iandDvGkL5' -O 'data.zip'\n",
        "!unzip -o data.zip -d ai-redditor/data/\n",
        "!rm data.zip \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (3.6.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.46.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (1.25.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2.9)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1diWV_PmttiuHQy-JQtNVs2iandDvGkL5\n",
            "To: /content/data.zip\n",
            "92.0MB [00:00, 178MB/s] \n",
            "Archive:  data.zip\n",
            "  inflating: ai-redditor/data/tifu_processed.data  \n",
            "  inflating: ai-redditor/data/writingprompts_full_processed.data  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcXjoo8NJtru",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "outputId": "dc041a64-70ba-4260-98e7-635eb3860cd5"
      },
      "source": [
        "#@title Finetune GPT2-XL\n",
        "#@markdown Finetune the extra-large pretrained GPT2 model consisting of 1.5 billion parameters using a TPU.\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "\n",
        "DATASET_PATH = \"ai-redditor/data/writingprompts_full_processed.data\"\n",
        "OUTPUT_DIRECTORY = \"./output/wp/\"\n",
        "NUM_TPU_CORES = 8\n",
        "\n",
        "!python xla_spawn.py --num_cores {NUM_TPU_CORES} \\\n",
        "          ai-redditor/ai-redditor/gpt2/train.py \\\n",
        "          {DATASET_PATH} \\\n",
        "          --do-train \\\n",
        "          --max-checkpoints 5 \\\n",
        "          --model-type \"gpt2-xl\" \\\n",
        "          --outdir {OUTPUT_DIRECTORY}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-06-22 01:52:18.303508: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-06-22 01:52:28.032919: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-06-22 01:52:28.045385: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-06-22 01:52:28.046969: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-06-22 01:52:28.095896: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-06-22 01:52:28.114987: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-06-22 01:52:28.118013: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-06-22 01:52:28.208673: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-06-22 01:52:28.289704: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-06-22 01:52:40.217015: I tensorflow/compiler/xla/xla_client/mesh_service.cc:234] Waiting to connect to client mesh master (300 seconds) 80a798f920cf:53165\n",
            "2020-06-22 01:52:40.233241: I tensorflow/compiler/xla/xla_client/mesh_service.cc:234] Waiting to connect to client mesh master (300 seconds) 80a798f920cf:53165\n",
            "2020-06-22 01:52:40.271590: I tensorflow/compiler/xla/xla_client/mesh_service.cc:234] Waiting to connect to client mesh master (300 seconds) 80a798f920cf:53165\n",
            "2020-06-22 01:52:40.319864: I tensorflow/compiler/xla/xla_client/mesh_service.cc:234] Waiting to connect to client mesh master (300 seconds) 80a798f920cf:53165\n",
            "2020-06-22 01:52:40.352974: I tensorflow/compiler/xla/xla_client/mesh_service.cc:234] Waiting to connect to client mesh master (300 seconds) 80a798f920cf:53165\n",
            "2020-06-22 01:52:40.385109: I tensorflow/compiler/xla/xla_client/mesh_service.cc:234] Waiting to connect to client mesh master (300 seconds) 80a798f920cf:53165\n",
            "2020-06-22 01:52:40.386540: I tensorflow/compiler/xla/xla_client/mesh_service.cc:234] Waiting to connect to client mesh master (300 seconds) 80a798f920cf:53165\n",
            "Downloading: 100% 665/665 [00:00<00:00, 179kB/s]\n",
            "Downloading:   0% 0.00/1.04M [00:00<?, ?B/s]2020-06-22 01:52:49.019317: I tensorflow/compiler/xla/xla_client/computation_client.cc:195] Fetching mesh configuration for worker tpu_worker:0 from mesh service at 80a798f920cf:53165\n",
            "Downloading: 100% 1.04M/1.04M [00:00<00:00, 5.86MB/s]\n",
            "2020-06-22 01:52:49.368670: I tensorflow/compiler/xla/xla_client/computation_client.cc:195] Fetching mesh configuration for worker tpu_worker:0 from mesh service at 80a798f920cf:53165\n",
            "Downloading: 100% 456k/456k [00:00<00:00, 3.75MB/s]\n",
            "2020-06-22 01:52:49.777368: I tensorflow/compiler/xla/xla_client/computation_client.cc:195] Fetching mesh configuration for worker tpu_worker:0 from mesh service at 80a798f920cf:53165\n",
            "2020-06-22 01:52:49.871714: I tensorflow/compiler/xla/xla_client/computation_client.cc:195] Fetching mesh configuration for worker tpu_worker:0 from mesh service at 80a798f920cf:53165\n",
            "2020-06-22 01:52:50.110989: I tensorflow/compiler/xla/xla_client/computation_client.cc:195] Fetching mesh configuration for worker tpu_worker:0 from mesh service at 80a798f920cf:53165\n",
            "Downloading:   0% 0.00/548M [00:00<?, ?B/s]2020-06-22 01:52:50.286181: I tensorflow/compiler/xla/xla_client/computation_client.cc:195] Fetching mesh configuration for worker tpu_worker:0 from mesh service at 80a798f920cf:53165\n",
            "Downloading:   1% 3.39M/548M [00:00<01:50, 4.95MB/s]2020-06-22 01:52:50.497636: I tensorflow/compiler/xla/xla_client/computation_client.cc:195] Fetching mesh configuration for worker tpu_worker:0 from mesh service at 80a798f920cf:53165\n",
            "Downloading: 100% 548M/548M [00:24<00:00, 22.2MB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"xla_spawn.py\", line 72, in <module>\n",
            "    main()\n",
            "  File \"xla_spawn.py\", line 68, in main\n",
            "/usr/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown\n",
            "  len(cache))\n",
            "    xmp.spawn(mod._mp_fn, args=(), nprocs=args.num_cores)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 293, in spawn\n",
            "    start_method=start_method)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/spawn.py\", line 158, in start_processes\n",
            "    while not context.join():\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/spawn.py\", line 108, in join\n",
            "    (error_index, name)\n",
            "Exception: process 5 terminated with signal SIGKILL\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}